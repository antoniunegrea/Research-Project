\documentclass[12pt]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{booktabs}
% ---------------------------------------------------------------------------------

\begin{document}

\title{A Novel Approach to Route Similarity Measures for Shared Mobility Matching Systems}
\author{Antoniu Negrea}
\date{2025}
\maketitle

\tableofcontents

\chapter{Modeling the Experimental Part}

This chapter rigorously describes the data used, the planned experiments,
the mathematical modeling of the similarity measures, the algorithms compared,
and the validation methods. The goal is to demonstrably prove, in a reproducible
and analytically supported manner, that the proposed approach brings
improvements over existing methods found in the literature.

\section{The Dataset}

\subsection{Representation of Urban Routes}

Each route is modeled as an ordered list of GPS points:
\[
R = \{ (lat_1, lon_1), \dots, (lat_n, lon_n) \}.
\]

The data sources are:
\begin{itemize}
\item simplified urban road network
\item artificially simulated routes for controlled scenarios
\end{itemize}

To reduce complexity, the GPS points are projected onto a
discretized network $G = (V, E)$, where $V$ are intersections and $E$ are segments.

\subsection{User Profiles}

Each user is associated with a triplet:
\[
U_i = (o_i, d_i, t_i),
\]
where $o_i$ is the origin, $d_i$ the destination, and $t_i$ the temporal interval (time window).

\section{Simplified Similarity Measures}

The proposed methodology uses two measures that are easy to implement:

\subsection{Geometric Similarity}

For two routes $R_1$, $R_2$:
\[
S_{geo}(R_1, R_2) = 1 - \frac{1}{|R_1|} \sum_{p \in R_1} \min_{q \in R_2} d(p,q),
\]
where $d(p,q)$ is the Haversine distance.

\subsection{Segment Overlap}

\[
S_{overlap}(R_1, R_2) = \frac{|R_1 \cap R_2|}{\max(|R_1|, |R_2|)}.
\]

\subsection{The Final Similarity Function}

A simple linear function:
\[
S_{final}(R_1, R_2) = \alpha S_{geo}(R_1, R_2) + \beta S_{overlap}(R_1, R_2),
\]
where $\alpha + \beta = 1$.

\section{Matching Algorithms}

\subsection{Static Matching — Partition Merging}

The objective is to group users such that the cost is minimized:
\[
\text{cost}(G) = \sum_{i,j \in G} (1 - S_{final}(R_i, R_j)).
\]

\subsection{Dynamic Matching — Greedy}

For a new request:
\[
\Delta \text{cost} = \text{cost}(G \cup \{U_k\}) - \text{cost}(G).
\]

The request is allocated to the group with the minimum $\Delta \text{cost}$.

\section{Proposed Experiments}

\subsection{Experiment 1: Static vs. Greedy}

The comparison between the two algorithms (Static Partition Merging and Dynamic Greedy) uses two principal metrics:
\begin{enumerate}
    \item \textbf{Efficiency} (Travel Gain): The reduction in total travel distance.
    \[
    \text{TravelGain} = \frac{D_{solo} - D_{shared}}{D_{solo}}.
    \]
    \item \textbf{Equity} (Maximum Relative Detour, MRD): The highest proportional increase in travel distance/time 
    experienced by any single rider in a shared group. This assesses the fairness of the solution.
\end{enumerate}

\subsection{Experiment 2: Impact of Parameters \(\alpha, \beta\)}

The influence of weights on matching quality is analyzed using both the \textbf{Travel Gain} and \textbf{MRD} metrics 
to assess the trade-off between efficiency and equity.

\subsection{Experiment 3: Scalability}

We measure:
\begin{itemize}
\item runtime;
\item memory used.
\end{itemize}

\section{Validation Methods}

Validation is exclusively numerical:

\subsection{Internal Validation}

Repeated simulations with artificially generated data.

\subsection{External Validation}

Comparison of results with:
\begin{itemize}
\item Xia \& Curtin (2019) – spatial model;
\item Duan (2018) – partition merging;
\item Sun (2023) – greedy.
\end{itemize}

\section{Conclusion}

The experimental model is simplified, reproducible, and easy to implement.
It allows for the evaluation of similarity functions and matching algorithms.

\chapter{Case Study on the Initial Dataset}

This chapter presents a controlled experiment performed on a small simulated
dataset to validate the proposed methodology in a simple scenario.

\section{Dataset Description}

The initial set contains:
\begin{itemize}
\item 10 short routes with controlled characteristics (50–200 m);
\item close or distant origins and destinations;
\item simple intersections for ease of implementation.
\end{itemize}

Three types of scenarios are included, each run with 10 routes:
\begin{enumerate}
\item nearly identical routes (IDENTICAL);
\item partially overlapping routes (PARTIAL);
\item completely different routes (DIFFERENT).
\end{enumerate}

\section{Experimental Code Implementation}

The practical component consists of implementing the following in Python:
\begin{itemize}
\item a route generator;
\item the $S_{geo}$ and $S_{overlap}$ functions;
\item the static and greedy algorithms;
\item the metrics measurement module.
\end{itemize}

Code structure:
\begin{verbatim}
ExperimentalPart/
    route_generator.py
    similarity.py
    static_matching.py
    greedy_matching.py
    metrics.py
    main.py
\end{verbatim}

\section{Results and Analysis}

The initial simulations were executed using $N=10$ routes per scenario, comparing the Static Matching (Partition Merging) against the Dynamic Matching (Greedy) approach. The results are summarized below.

\subsection{Experiment 1: Static vs. Greedy (\(\alpha=\beta=0.5\))}

The initial experiment focuses on baseline performance using balanced similarity weights.

\begin{table}[htbp]
    \centering
    \caption{Experiment 1: Static vs. Greedy Comparison (\(\alpha=0.5, \beta=0.5\))}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Scenario} & \textbf{Algorithm} & \textbf{Groups} & \textbf{Avg. Size} & \textbf{Travel Gain} & \textbf{MRD} \\
        \midrule
        IDENTICAL & Static & 1 & 10.00 & 90.00\% & 0.00\% \\
        & Greedy & 1 & 10.00 & 90.00\% & 0.00\% \\
        \midrule
        PARTIAL & Static & 6 & 1.67 & 18.87\% & 50.00\% \\
        & Greedy & 6 & 1.67 & 15.09\% & 50.00\% \\
        \midrule
        DIFFERENT & Static & 8 & 1.25 & 7.69\% & 100.00\% \\
        & Greedy & 6 & 1.67 & 15.38\% & 100.00\% \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{itemize}
    \item \textbf{Identical Scenario:} As expected, both algorithms performed optimally, merging all 10 routes into a single group, yielding the maximum possible 90.00\% Travel Gain and zero detour (0.00\% MRD). This validates the algorithms' ability to identify perfect matches.
    \item \textbf{Partial Scenario:} The \textbf{Static Matching} algorithm achieved a slightly higher Travel Gain (18.87\%) compared to the Greedy approach (15.09\%), indicating that its global optimization view resulted in marginally more efficient overall groupings, even though both formed the same number of groups (6) and had the same average size (1.67) and MRD (50.00\%).
    \item \textbf{Different Scenario:} The results here are highly revealing. While both algorithms correctly showed low efficiency and high detours (100.00\% MRD), the Greedy algorithm unexpectedly yielded a better Travel Gain (15.38\% vs. Static's 7.69\%) despite forming fewer groups (6 vs. 8). This suggests that in scenarios with poor inherent matchability, the sequential nature of the Greedy algorithm might, by chance, establish a few highly efficient initial groups that the Static algorithm's global, similarity-driven cost function failed to identify under this specific weight setting.
\end{itemize}

\subsection{Experiment 2: Impact of Parameters (\(\alpha, \beta\)) on 'Partial' Scenario}

This experiment used the PARTIAL scenario as a testbed to analyze how the relative weighting of geometric similarity ($\alpha$) versus segment overlap ($\beta$) affects efficiency and equity.

\begin{table}[htbp]
    \centering
    \caption{Experiment 2: Parameter Impact on Matching Quality (PARTIAL Scenario)}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{$\alpha$} & \textbf{$\beta$} & \textbf{Algorithm} & \textbf{Travel Gain} & \textbf{MRD} \\
        \midrule
        0.1 & 0.9 & Static & 25.45\% & 0.00\% \\
        (Overlap-Heavy) & & Greedy & 25.45\% & 0.00\% \\
        \midrule
        0.5 & 0.5 & Static & 29.09\% & 20.00\% \\
        (Balanced) & & Greedy & 20.00\% & 50.00\% \\
        \midrule
        0.9 & 0.1 & Static & 29.09\% & 20.00\% \\
        (Geometric-Heavy) & & Greedy & \textbf{30.91\%} & 50.00\% \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{itemize}
    \item \textbf{Geometric-Heavy ($\alpha=0.9, \beta=0.1$):} This setting proved to be the most successful for maximizing efficiency, with the \textbf{Greedy algorithm achieving the highest Travel Gain (30.91\%)} across all tests. This result confirms that $S_{geo}$ (geometric proximity) is the most informative metric in our similarity function. However, the Static algorithm achieved a high gain (29.09\%) while maintaining a significantly lower detour (\textbf{MRD 20.00\%} vs. Greedy's 50.00\%), highlighting the trade-off: Static matching offers superior equity for similar efficiency.
    \item \textbf{Overlap-Heavy ($\alpha=0.1, \beta=0.9$):} This setting resulted in perfect equity (0.00\% MRD) for both algorithms, but at the cost of constrained efficiency (25.45\% gain). This high $\beta$ weight makes the similarity function overly strict, only permitting near-identical route matches, which limits the potential for efficiency gains by excluding feasible, but slightly detoured, matches.
\end{itemize}

\section{Conclusion}

The initial set \textbf{quantitatively confirms} that the two simple similarity measures are sufficient for
relevant and measurable experiments. The results validate the model by demonstrating clear performance differences—for
instance, the dependence on parameter weighting and the inherent trade-off between the Static (equity-focused) and Greedy (efficiency-focused) algorithms. The experiments successfully demonstrated the sensitivity and impact of the final similarity
function's weighting, with the $S_{geo}$ component proving to be a critical factor for high-quality matching.

\end{document}